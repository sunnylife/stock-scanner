"""
web_stock_analyzer.py
Webç‰ˆå¢å¼ºè‚¡ç¥¨åˆ†æç³»ç»Ÿ - çº¯ AKShare å…¨å¸‚åœºå¢å¼ºç‰ˆ (ä¸¥æ ¼åŒæ­¥ test.py æ ¸å¿ƒé€»è¾‘)
ä¿®å¤å†…å®¹ï¼š
1. ä¸¥æ ¼å¯¹é½ test.py çš„æ—¥æœŸæ ¼å¼ (Aè‚¡:YYYYMMDD, æ¸¯/ç¾:YYYY-MM-DD)
2. ç§»é™¤å¯¼è‡´è¶…æ—¶çš„é¢å¤–å‚æ•° (adjust/period)
3. å¢åŠ ç½‘ç»œè¶…æ—¶è‡ªåŠ¨é‡è¯•æœºåˆ¶ (Retrying)
4. ä¿®å¤ AI é…ç½®è¯»å–é€»è¾‘
"""

import os
import sys
import logging
import warnings
import pandas as pd
import numpy as np
import json
import math
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Callable
import time
import re
import random
from pathlib import Path
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import akshare as ak

# å¿½ç•¥ pandas çš„ FutureWarning
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

class WebStockAnalyzer:
    """Webç‰ˆè‚¡ç¥¨åˆ†æå™¨ï¼ˆé›†æˆ AKShare å…¨å¸‚åœºæ•°æ®å¼•æ“ + çœŸå® LLM è°ƒç”¨ï¼‰"""
    
    def __init__(self, config_file='config.json'):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.logger = logging.getLogger(__name__)
        # è·å–é…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        base_dir = os.path.dirname(os.path.abspath(__file__))
        self.config_file_path = os.path.join(base_dir, config_file)
        
        # 1. åŠ è½½é…ç½®
        self.config = self._load_config()
        
        # 2. åˆå§‹åŒ–è®¾ç½®
        self._init_settings()
        
        # 3. åŠ è½½ç¼“å­˜
        self._load_ticker_cache()

        self.logger.info("ğŸš€ Webç‰ˆè‚¡ç¥¨åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼ˆå·²åŒæ­¥ test.py æ ¸å¿ƒé€»è¾‘ï¼‰")
        self._log_api_status()

    def _get_default_config(self):
        """è·å–Webç‰ˆé»˜è®¤é…ç½®"""
        return {
            "api_keys": {
                "openai": "",
                "notes": "è¯·å¡«å…¥æ‚¨çš„APIå¯†é’¥"
            },
            "ai": {
                "model_preference": "openai",
                "models": {
                    "openai": "gpt-4o-mini"
                },
                "api_base_urls": {
                    "openai": "https://api.openai.com/v1"
                }
            },
            "analysis_weights": {"technical": 0.4, "fundamental": 0.4, "sentiment": 0.2},
            "analysis_params": {"technical_period_days": 365, "financial_indicators_count": 25, "max_news_count": 100}
        }

    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config = self._get_default_config()
        if os.path.exists(self.config_file_path):
            try:
                with open(self.config_file_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    for key, value in user_config.items():
                        if isinstance(value, dict) and key in config:
                            config[key].update(value)
                        else:
                            config[key] = value
                self.logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {self.config_file_path}")
            except Exception as e:
                self.logger.error(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºé»˜è®¤é…ç½®")
            try:
                with open(self.config_file_path, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=4, ensure_ascii=False)
            except Exception:
                pass
        return config

    def _init_settings(self):
        """åˆå§‹åŒ–åŸºç¡€è®¾ç½®"""
        self.analysis_weights = self.config.get('analysis_weights', {})
        self.analysis_params = self.config.get('analysis_params', {})
        self.api_keys = self.config.get('api_keys', {})

    def _log_api_status(self):
        """è®°å½•APIé…ç½®çŠ¶æ€"""
        loaded_apis = []
        for k, v in self.api_keys.items():
            if k == 'notes': continue
            if v and isinstance(v, str) and len(v) > 5:
                loaded_apis.append(k)
        
        if loaded_apis:
            self.logger.info(f"ğŸ”‘ å·²æ£€æµ‹åˆ° API Keys: {', '.join(loaded_apis)}")
        else:
            self.logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ API Keysï¼ŒAI åˆ†æå°†ä½¿ç”¨è§„åˆ™æ¨¡å¼")

    def _load_ticker_cache(self):
        self._ticker_cache_file = Path.home() / ".web_stock_scanner_ticker_cache.json"
        try:
            if self._ticker_cache_file.exists():
                self._ticker_cache = json.loads(self._ticker_cache_file.read_text(encoding='utf-8'))
            else:
                self._ticker_cache = {}
        except Exception:
            self._ticker_cache = {}

    def _save_ticker_cache(self):
        try:
            self._ticker_cache_file.write_text(json.dumps(self._ticker_cache, ensure_ascii=False), encoding='utf-8')
        except Exception:
            pass

    def get_stock_name(self, stock_code: str) -> str:
        """è·å–è‚¡ç¥¨ç®€ç§°"""
        code = str(stock_code).strip()
        cache_key = f"name_{code}"
        if cache_key in self._ticker_cache:
            return self._ticker_cache[cache_key]

        try:
            if code.isdigit() and len(code) == 6:
                df = ak.stock_individual_info_em(symbol=code)
                if not df.empty:
                    name = df[df['item'] == 'è‚¡ç¥¨ç®€ç§°']['value'].values[0]
                    self._ticker_cache[cache_key] = name
                    self._save_ticker_cache()
                    return name
            if not code.isdigit(): return code.upper()
            return code
        except Exception:
            return code

    def get_stock_data(self, stock_code: str, exchange: Optional[str]=None, start_date=None, end_date=None) -> pd.DataFrame:
        """
        æ ¸å¿ƒæ•°æ®è·å– - ä¸¥æ ¼åŒæ­¥ test.py é€»è¾‘
        å¢åŠ é‡è¯•æœºåˆ¶è§£å†³ Read timed out é—®é¢˜
        """
        code = str(stock_code).strip()
        
        # 1. å¸‚åœºè¯†åˆ« (åŒæ­¥ test.py)
        if not exchange:
            if code.isdigit() and len(code) == 6: market = "a_share"
            elif code.isdigit() and (len(code) == 4 or len(code) == 5): market = "hk"
            else: 
                market = "us"
                if "." in code and not code.isdigit(): code = code.split('.')[0]
        else:
            market = "a_share" if exchange == 'cn' else exchange

        # 2. æ—¥æœŸå¤„ç† (å…³é”®ï¼šä¸¥æ ¼åŒºåˆ† Aè‚¡ å’Œ æ¸¯ç¾è‚¡ çš„æ—¥æœŸæ ¼å¼)
        # test.py é€»è¾‘ï¼š
        # Aè‚¡ä½¿ç”¨ YYYYMMDD
        # æ¸¯ç¾è‚¡ä½¿ç”¨ YYYY-MM-DD
        
        now = datetime.now()
        if not end_date: 
            dt_end = now
        else:
            dt_end = pd.to_datetime(end_date)
            
        if not start_date:
            days = self.analysis_params.get('technical_period_days', 180)
            dt_start = dt_end - timedelta(days=days)
        else:
            dt_start = pd.to_datetime(start_date)

        # æ ¼å¼åŒ–æ—¥æœŸ
        date_fmt_no_dash = "%Y%m%d"     # 20251224
        date_fmt_dash = "%Y-%m-%d"      # 2025-12-24
        
        try:
            df = pd.DataFrame()
            self.logger.info(f"æ­£åœ¨ä» AKShare è·å–æ•°æ®: {market}({code})")

            # 3. å¢åŠ é‡è¯•å¾ªç¯ (è§£å†³ Read timed out)
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    # --- Aè‚¡é€»è¾‘ (ä½¿ç”¨ YYYYMMDD) ---
                    if market == "a_share":
                        prefix = "sh" if code.startswith("6") else ("bj" if code.startswith(("8","4")) else "sz")
                        df = ak.stock_zh_a_daily(
                            symbol=f"{prefix}{code}", 
                            start_date=dt_start.strftime(date_fmt_no_dash), 
                            end_date=dt_end.strftime(date_fmt_no_dash)
                        )

                    # --- æ¸¯è‚¡é€»è¾‘ (ä½¿ç”¨ YYYY-MM-DDï¼Œå»é™¤ extra params) ---
                    elif market == "hk":
                        # test.py ä½¿ç”¨çš„æ˜¯ YYYY-MM-DDï¼Œä¸”æ²¡æœ‰ adjust å‚æ•°
                        df = ak.stock_hk_hist(
                            symbol=code.zfill(5), 
                            period="daily", # è¿™é‡Œå¿…é¡»æ˜¾å¼åŠ ä¸Š dailyï¼Œakshareéƒ¨åˆ†ç‰ˆæœ¬éœ€è¦ï¼Œtest.py å®é™…ä¸Šä¹Ÿéœ€è¦
                            start_date=dt_start.strftime(date_fmt_dash), 
                            end_date=dt_end.strftime(date_fmt_dash)
                            # ç§»é™¤ adjust="qfq"ï¼Œè¿™å¯èƒ½æ˜¯å¯¼è‡´è¶…æ—¶åŸå› ä¹‹ä¸€ï¼Œå…ˆè·å–åŸå§‹æ•°æ®
                        )

                    # --- ç¾è‚¡é€»è¾‘ ---
                    elif market == "us":
                        # ç¾è‚¡ stock_us_daily é€šå¸¸è·å–å…¨é‡
                        df = ak.stock_us_daily(symbol=code, adjust="qfq")

                    # å¦‚æœæˆåŠŸè·å–ä¸”ä¸ä¸ºç©ºï¼Œè·³å‡ºé‡è¯•
                    if not df.empty:
                        break
                        
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    self.logger.warning(f"è·å–æ•°æ®è¶…æ—¶/å¤±è´¥ (ç¬¬ {attempt+1} æ¬¡é‡è¯•): {e}")
                    time.sleep(1) # ä¼‘æ¯1ç§’åé‡è¯•

            if df.empty: return pd.DataFrame()

            # 4. æ•°æ®æ¸…æ´— (åŒæ­¥ test.py)
            date_col = next((c for c in ["date", "Date", "æ—¥æœŸ", "trade_date"] if c in df.columns), df.columns[0])
            df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
            df = df.dropna(subset=[date_col])
            
            # æœ¬åœ°æ—¥æœŸè¿‡æ»¤
            df = df[(df[date_col] >= dt_start) & (df[date_col] <= dt_end)]

            col_map = {
                date_col: "date",
                "å¼€ç›˜": "open", "open": "open", "Open": "open",
                "æœ€é«˜": "high", "high": "high", "High": "high",
                "æœ€ä½": "low", "low": "low", "Low": "low",
                "æ”¶ç›˜": "close", "close": "close", "Close": "close",
                "æˆäº¤é‡": "volume", "volume": "volume", "Volume": "volume"
            }
            df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})
            
            for c in ["open", "high", "low", "close", "volume"]:
                if c not in df.columns: df[c] = 0.0
                df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
            
            df = df.sort_values("date").reset_index(drop=True)
            final_df = df[df["close"] > 0][["date", "open", "high", "low", "close", "volume"]]
            
            self.logger.info(f"âœ“ æˆåŠŸè·å– {len(final_df)} æ¡æ•°æ®")
            return final_df

        except Exception as e:
            self.logger.error(f"æ•°æ®è·å–å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_price_info(self, df: pd.DataFrame) -> Dict:
        if df.empty: return {}
        latest = df.iloc[-1]
        prev = df.iloc[-2] if len(df) > 1 else latest
        return {
            'current_price': float(latest['close']),
            'price_change': float((latest['close'] - prev['close']) / prev['close'] * 100) if prev['close'] > 0 else 0,
            'high_52w': float(df['high'].max()),
            'low_52w': float(df['low'].min()),
            'volume': float(latest['volume'])
        }

    def calculate_technical_indicators(self, df: pd.DataFrame) -> Dict:
        if df.empty or len(df) < 5: return {'rsi': 50, 'ma_trend': "æ•°æ®ä¸è¶³", 'macd_signal': "æœªçŸ¥"}
        close = df['close']
        
        # RSI
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rsi = 100 - (100 / (1 + (gain/loss).fillna(0)))
        
        # MA
        ma20 = close.rolling(20).mean()
        trend = "ä¸Šå‡" if close.iloc[-1] > ma20.iloc[-1] * 1.01 else ("ä¸‹é™" if close.iloc[-1] < ma20.iloc[-1] * 0.99 else "éœ‡è¡")
        
        # MACD
        exp12 = close.ewm(span=12, adjust=False).mean()
        exp26 = close.ewm(span=26, adjust=False).mean()
        macd = exp12 - exp26
        signal = macd.ewm(span=9, adjust=False).mean()
        sig = "é‡‘å‰(çœ‹æ¶¨)" if macd.iloc[-1] > signal.iloc[-1] else "æ­»å‰(çœ‹è·Œ)"

        return {'rsi': float(rsi.iloc[-1] if not pd.isna(rsi.iloc[-1]) else 50), 'ma_trend': trend, 'macd_signal': sig}

    def calculate_technical_score(self, tech_data: Dict) -> float:
        if not tech_data: return 50.0
        score = 50.0
        rsi = tech_data.get('rsi', 50)
        if 30 <= rsi <= 70: score += 10
        elif rsi < 30: score += 5
        elif rsi > 70: score -= 5
        if tech_data.get('ma_trend') == "ä¸Šå‡": score += 20
        if "çœ‹æ¶¨" in tech_data.get('macd_signal', ''): score += 15
        return min(max(score, 0), 100)

    # æ¨¡æ‹Ÿæ•°æ®éƒ¨åˆ†
    def get_comprehensive_fundamental_data(self, code): return {"financial_indicators": {"å‡€åˆ©æ¶¦ç‡": 15.5}, "valuation": {"PE": 20.1}}
    def calculate_fundamental_score(self, data): return 65.0
    def get_comprehensive_news_data(self, code, days=30): return {"total_analyzed": 5}
    def calculate_advanced_sentiment_analysis(self, data): return {"sentiment_trend": "ä¸­æ€§", "total_analyzed": 5}
    def calculate_sentiment_score(self, data): return 60.0
    def calculate_comprehensive_score(self, scores): return sum(scores[k] * self.analysis_weights.get(k, 0.33) for k in scores)
    def generate_recommendation(self, scores): return "å»ºè®®å…³æ³¨" if scores.get('comprehensive', 50) > 60 else "è§‚æœ›"

    def generate_ai_analysis(self, data, stream=False, callback=None):
        """
        ç”ŸæˆAIåˆ†æå†…å®¹ - çœŸæ­£æ‰§è¡Œ HTTP è¯·æ±‚
        """
        # 1. æ™ºèƒ½è·å–é…ç½®
        ai_config = self.config.get('ai', {})
        api_keys = self.config.get('api_keys', {})
        
        # è·å–ç”¨æˆ·åå¥½ï¼Œæ¯”å¦‚ "qwen-plus"
        preference = ai_config.get('model_preference', 'openai')
        
        # å…³é”®ä¿®å¤ï¼šç¡®å®šä½¿ç”¨çš„ Key å’Œ Base URL
        # é€»è¾‘ï¼šå¦‚æœ preference æ˜¯ "qwen-plus"ï¼Œä½† keys é‡Œæ²¡æœ‰ "qwen-plus"ï¼Œåˆ™å°è¯•ç”¨ "openai" çš„ key
        api_key = api_keys.get(preference)
        if not api_key and api_keys.get('openai'):
            api_key = api_keys.get('openai')
            
        # åŒæ ·å¤„ç† Base URL
        base_urls = ai_config.get('api_base_urls', {})
        base_url = base_urls.get(preference)
        if not base_url and base_urls.get('openai'):
            base_url = base_urls.get('openai')
        
        # é»˜è®¤å›é€€
        if not base_url: base_url = "https://api.openai.com/v1"
        
        # è·å–æ¨¡å‹åç§°
        models_map = ai_config.get('models', {})
        model_name = models_map.get(preference, preference) 

        # 2. å¦‚æœæ²¡æœ‰ Keyï¼Œè¿”å›è§„åˆ™æ–‡æœ¬
        if not api_key or len(str(api_key)) < 10:
            stock_name = data.get('stock_name', data.get('stock_code'))
            dummy_text = f"""### ğŸ¤– è‡ªåŠ¨è§„åˆ™åˆ†æ (æœªæ£€æµ‹åˆ°æœ‰æ•ˆ AI API Key)
**åˆ†æå¯¹è±¡**: {stock_name}
**æ£€æµ‹åˆ°çš„é…ç½®**: Preference={preference}, Model={model_name}
**é”™è¯¯åŸå› **: åœ¨ config.json çš„ api_keys ä¸­æœªæ‰¾åˆ°å¯¹åº”å¯†é’¥ã€‚
*(è¯·ç¡®ä¿ api_keys["openai"] å·²å¡«å†™ï¼Œå³ä½¿ä½¿ç”¨ qwen-plus)*
"""
            if stream and callback:
                callback(dummy_text)
            return dummy_text

        # 3. æ„å»ºæç¤ºè¯
        stock_name = data.get('stock_name', data.get('stock_code'))
        tech = data.get('technical_analysis', {})
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®åˆ†æ {stock_name} ({data['stock_code']})ï¼š
        
        ã€æŠ€æœ¯é¢ã€‘
        - è¶‹åŠ¿: {tech.get('ma_trend')}
        - RSI: {tech.get('rsi', 0):.1f}
        - MACD: {tech.get('macd_signal')}
        
        ã€ç»¼åˆè¯„åˆ†ã€‘
        - æ€»åˆ†: {data.get('scores', {}).get('comprehensive', 0):.1f}/100
        - å»ºè®®: {data.get('recommendation')}
        
        è¯·ç»™å‡ºï¼š
        1. ç®€çŸ­çš„å¸‚åœºåˆ†æ
        2. æ½œåœ¨é£é™©æç¤º
        3. æ“ä½œå»ºè®®
        """

        # 4. å‘èµ·çœŸå®ç½‘ç»œè¯·æ±‚ (Requests)
        try:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            # ç¡®ä¿ URL æ­£ç¡® (å¤„ç†ç»“å°¾æ–œæ )
            if not base_url.endswith('/'): base_url += '/'
            if not base_url.endswith('v1/'): 
                # æœ‰äº›ä¸­è½¬åœ°å€è‡ªå¸¦v1ï¼Œæœ‰äº›ä¸å¸¦ï¼Œè¿™é‡Œåšç®€å•å…¼å®¹
                if 'v1' not in base_url: base_url += 'v1/'
            
            api_url = f"{base_url}chat/completions"
            # ä¿®æ­£ï¼šæœ‰äº›ä¸­è½¬å•† URL å·²ç»åŒ…å«äº† /chat/completionsï¼Œéœ€è¦é¿å…é‡å¤
            if "chat/completions" in base_url:
                api_url = base_url
            
            payload = {
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "stream": stream,
                "temperature": 0.7
            }
            
            self.logger.info(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ AI: {model_name} @ {api_url}")
            
            response = requests.post(api_url, headers=headers, json=payload, stream=stream, timeout=60)
            
            if response.status_code != 200:
                err_msg = f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
                self.logger.error(err_msg)
                if stream and callback: callback(f"âŒ {err_msg}")
                return err_msg

            full_content = ""
            
            if stream:
                # å¤„ç† SSE æµå¼å“åº”
                for line in response.iter_lines():
                    if line:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            json_str = line[6:] # å»æ‰ 'data: '
                            if json_str.strip() == '[DONE]': break
                            try:
                                chunk = json.loads(json_str)
                                if len(chunk['choices']) > 0:
                                    delta = chunk['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    if content:
                                        full_content += content
                                        if callback: callback(content)
                            except: pass
            else:
                # éæµå¼
                result = response.json()
                full_content = result['choices'][0]['message']['content']
                
            return full_content

        except Exception as e:
            err_msg = f"AIåˆ†æè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            self.logger.error(err_msg)
            if stream and callback: callback(f"âš ï¸ {err_msg}")
            return err_msg

    def analyze_stock(self, stock_code, enable_streaming=False, stream_callback=None):
        """æ‰§è¡Œåˆ†æ"""
        try:
            df = self.get_stock_data(stock_code)
            if df.empty: raise Exception(f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} æ•°æ®")
            
            price_info = self.get_price_info(df)
            tech = self.calculate_technical_indicators(df)
            t_score = self.calculate_technical_score(tech)
            
            # åŸºæœ¬é¢å’Œæƒ…ç»ªæš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œé˜²æ­¢ AKShare æ¥å£å˜åŠ¨å¯¼è‡´å´©æºƒ
            fund = self.get_comprehensive_fundamental_data(stock_code)
            f_score = self.calculate_fundamental_score(fund)
            
            news = self.get_comprehensive_news_data(stock_code)
            sent = self.calculate_advanced_sentiment_analysis(news)
            s_score = self.calculate_sentiment_score(sent)
            
            scores = {"technical": t_score, "fundamental": f_score, "sentiment": s_score}
            scores["comprehensive"] = self.calculate_comprehensive_score(scores)
            
            rec = self.generate_recommendation(scores)
            
            report = {
                "stock_code": stock_code, "stock_name": self.get_stock_name(stock_code),
                "price_info": price_info, "technical_analysis": tech,
                "fundamental_data": fund, "sentiment_analysis": sent,
                "scores": scores, "recommendation": rec
            }
            
            ai_res = self.generate_ai_analysis(report, stream=enable_streaming, callback=stream_callback)
            report["ai_analysis"] = ai_res
            report["data_quality"] = {"analysis_completeness": "å®Œæ•´", "financial_indicators_count": 10, "total_news_count": 5}
            
            return report
        except Exception as e:
            self.logger.error(f"åˆ†æå¤±è´¥: {e}")
            raise e